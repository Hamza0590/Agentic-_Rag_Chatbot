{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b9e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "doc = fitz.open(r\"E:\\SEMESTER 1\\PF~ADIL SHEHZAD\\BOOKS\\C++ How to Program, 10th edition.pdf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd40c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Show all output, not just last expression\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Increase max output length\n",
    "from IPython.display import HTML\n",
    "import sys\n",
    "sys.stdout.write = lambda x: HTML(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bedf110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumperina\n",
      "\n",
      "Page 1:\n",
      "  Text blocks: 2\n",
      "  Images: 1\n",
      "\n",
      "Page 2:\n",
      "  Text blocks: 0\n",
      "  Images: 1\n",
      "This page intentionally left blank\n",
      "\n",
      "Page 3:\n",
      "  Text blocks: 1\n",
      "  Images: 0\n",
      "Paul Deitel\n",
      "Deitel & Associates, Inc.\n",
      "Harvey Deitel\n",
      "Deitel & Associates, Inc.\n",
      "\n",
      "Page 4:\n",
      "  Text blocks: 2\n",
      "  Images: 1\n",
      "Vice President, Editorial Director: Marcia Horton\n",
      "Acquisitions Editor: Tracy Johnson\n",
      "Editorial Assistant: Kristy Alaura\n",
      "Acquisitions Editor, Global Editions: Sourabh Maheshwari\n",
      "VP of Marketing: Christy Lesko\n",
      "Director of Field Marketing: Tim Galligan\n",
      "Product Marketing Manager: Bram Van Kempen\n",
      "Field Marketing Manager: Demetrius Hall\n",
      "Marketing Assistant: Jon Bryant\n",
      "Director of Product Management: Erin Gregg\n",
      "Team Lead, Program and Project Management: Scott Disanno\n",
      "Program Manager: Carole Snyder\n",
      "Project Manager: Robert Engelhardt\n",
      "Project Editor, Global Editions: K.K. Neelakantan\n",
      "Senior Manufacturing Controller, Global Editions: Trudy Kimber\n",
      "Senior Specialist, Program Planning and Support: Maura Zaldivar-Garcia\n",
      "Media Production Manager, Global Editions: Vikram Kumar\n",
      "Cover Art: Finevector / Shutterstock\n",
      "Cover Design: Lumina Datamatics\n",
      "R&P Manager: Rachel Youdelman\n",
      "R&P Project Manager: Timothy Nicholls\n",
      "Inventory Manager: Meredith Maresca\n",
      "Credits and acknowledgments borrowed from other sources and reproduced, with permission, in this textbook appear\n",
      "on page 6.\n",
      "Pearson Education Limited\n",
      "Edinburgh Gate\n",
      "Harlow\n",
      "Essex CM20 2JE\n",
      "England\n",
      "and Associated Companies throughout the world\n",
      "Visit us on the World Wide Web at:\n",
      "www.pearsonglobaleditions.com\n",
      "© Pearson Education Limited 2017\n",
      "The rights of Paul Deitel and Harvey Deitel to be identified as the authors of this work have been asserted by them in \n",
      "accordance with the Copyright, Designs and Patents Act 1988.\n",
      "Authorized adaptation from the United States edition, entitled C++ How to Program,10th Edition, ISBN \n",
      "9780134448237, by Paul Deitel and Harvey Deitel published by Pearson Education © 2017.\n",
      "All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any \n",
      "form or by any means, electronic, mechanical, photocopying, recording or otherwise, without either the prior written \n",
      "permission of the publisher or a license permitting restricted copying in the United Kingdom issued by the Copyright \n",
      "Licensing Agency Ltd, Saffron House, 6–10 Kirby Street, London EC1N 8TS.\n",
      "All trademarks used herein are the property of their respective owners. The use of any trademark in this text does not \n",
      "vest in the author or publisher any trademark ownership rights in such trademarks, nor does the use of such trademarks \n",
      "imply any affiliation with or endorsement of this book by such owners.\n",
      "British Library Cataloguing-in-Publication Data\n",
      "A catalogue record for this book is available from the British Library\n",
      "10  9  8  7  6  5  4  3  2  1\n",
      "ISBN 10: 1-292-15334-2\n",
      "ISBN 13: 978-1-292-15334-6\n",
      "Typeset by GEX Publishing Services\n",
      "Printed and bound in Malaysia\n",
      "\n",
      "Page 5:\n",
      "  Text blocks: 17\n",
      "  Images: 0\n",
      "In memory of Marvin Minsky,\n",
      "a founding father of the \n",
      "field of artificial intelligence.\n",
      "It was a privilege to be your student in two graduate \n",
      "courses at M.I.T.  Every lecture you gave inspired \n",
      "your students to think beyond limits. \n",
      "Harvey Deitel\n",
      "\n",
      "Page 6:\n",
      "  Text blocks: 3\n",
      "  Images: 0\n",
      "Trademarks \n",
      "DEITEL and the double-thumbs-up bug are registered trademarks of Deitel and Associates, Inc.\n",
      "Carnegie Mellon Software Engineering Institute™ is a trademark of Carnegie Mellon University.\n",
      "CERT® is registered in the U.S. Patent and Trademark Office by Carnegie Mellon University.\n",
      "UNIX is a registered trademark of The Open Group.\n",
      "Microsoft and/or its respective suppliers make no representations about the suitability of the information \n",
      "contained in the documents and related graphics published as part of the services for any purpose. All \n",
      "such documents and related graphics are provided “as is” without warranty of any kind. Microsoft and/\n",
      "or its respective suppliers hereby disclaim all warranties and conditions with regard to this information, \n",
      "including all warranties and conditions of merchantability, whether express, implied or statutory, fitness \n",
      "for a particular purpose, title and non-infringement. In no event shall Microsoft and/or its respective sup-\n",
      "pliers be liable for any special, indirect or consequential damages or any damages whatsoever resulting \n",
      "from loss of use, data or profits, whether in an action of contract, negligence or other tortious action, \n",
      "arising out of or in connection with the use or performance of information available from the services.\n",
      "The documents and related graphics contained herein could include technical inaccuracies or typograph-\n",
      "ical errors. Changes are periodically added to the information herein. Microsoft and/or its respective sup-\n",
      "pliers may make improvements and/or changes in the product(s) and/or the program(s) described herein \n",
      "at any time. Partial screen shots may be viewed in full within the software version specified.\n",
      "Microsoft® and Windows® are registered trademarks of the Microsoft Corporation in the U.S.A. and \n",
      "other countries. Screen shots and icons reprinted with permission from the Microsoft Corporation. This \n",
      "book is not sponsored or endorsed by or affiliated with the Microsoft Corporation.\n",
      "Throughout this book, trademarks are used. Rather than put a trademark symbol in every occurrence of \n",
      "a trademarked name, we state that we are using the names in an editorial fashion only and to the benefit \n",
      "of the trademark owner, with no intention of infringement of the trademark.\n",
      "\n",
      "Page 7:\n",
      "  Text blocks: 9\n",
      "  Images: 0\n",
      "Chapters 23–26 and Appendices F–J are PDF documents posted online at the book’s\n",
      "Companion Website, which is accessible from \n",
      "See the inside front cover for more information.\n",
      "Preface \n",
      " 23\n",
      "Before You Begin \n",
      " 39\n",
      "1\n",
      "Introduction to Computers and C++ \n",
      " 41\n",
      "1.1\n",
      "Introduction \n",
      " 42\n",
      "1.2\n",
      "Computers and the Internet in Industry and Research \n",
      " 43\n",
      "1.3\n",
      "Hardware and Software \n",
      " 45\n",
      "1.3.1\n",
      "Moore’s Law \n",
      " 45\n",
      "1.3.2\n",
      "Computer Organization \n",
      " 46\n",
      "1.4\n",
      "Data Hierarchy \n",
      " 47\n",
      "1.5\n",
      "Machine Languages, Assembly Languages and High-Level Languages \n",
      " 50\n",
      "1.6\n",
      "C and C++ \n",
      " 51\n",
      "1.7\n",
      "Programming Languages \n",
      " 52\n",
      "1.8\n",
      "Introduction to Object Technology \n",
      " 54\n",
      "1.9\n",
      "Typical C++ Development Environment \n",
      " 57\n",
      "1.10\n",
      "Test-Driving a C++ Application \n",
      " 60\n",
      "1.10.1\n",
      "Compiling and Running an Application in Visual Studio 2015 \n",
      "for Windows \n",
      " 60\n",
      "1.10.2\n",
      "Compiling and Running Using GNU C++ on Linux \n",
      " 65\n",
      "1.10.3\n",
      "Compiling and Running with Xcode on Mac OS X \n",
      " 67\n",
      "1.11\n",
      "Operating Systems \n",
      " 72\n",
      "1.11.1\n",
      "Windows—A Proprietary Operating System \n",
      " 72\n",
      "1.11.2\n",
      "Linux—An Open-Source Operating System \n",
      " 72\n",
      "1.11.3\n",
      "Apple’s OS X; Apple’s iOS for iPhone®, iPad® and iPod Touch® \n",
      "Devices \n",
      " 73\n",
      "1.11.4\n",
      "Google’s Android \n",
      " 73\n",
      "1.12\n",
      "The Internet and the World Wide Web \n",
      " 74\n",
      "1.13\n",
      "Some Key Software Development Terminology \n",
      " 76\n",
      "1.14\n",
      "C++11 and C++14: The Latest C++ Versions \n",
      " 78\n",
      "http://www.pearsonglobaleditions.com/deitel\n",
      "Contents\n",
      "\n",
      "Page 8:\n",
      "  Text blocks: 7\n",
      "  Images: 1\n",
      "8\n",
      "Contents\n",
      "1.15\n",
      "Boost C++ Libraries \n",
      " 79\n",
      "1.16\n",
      "Keeping Up to Date with Information Technologies \n",
      " 79\n",
      "2\n",
      "Introduction to C++ Programming, \n",
      "Input/Output and Operators \n",
      " 84\n",
      "2.1\n",
      "Introduction \n",
      " 85\n",
      "2.2\n",
      "First Program in C++: Printing a Line of Text \n",
      " 85\n",
      "2.3\n",
      "Modifying Our First C++ Program \n",
      " 89\n",
      "2.4\n",
      "Another C++ Program: Adding Integers \n",
      " 90\n",
      "2.5\n",
      "Memory Concepts \n",
      " 94\n",
      "2.6\n",
      "Arithmetic \n",
      " 95\n",
      "2.7\n",
      "Decision Making: Equality and Relational Operators \n",
      " 99\n",
      "2.8\n",
      "Wrap-Up \n",
      " 103\n",
      "3\n",
      "Introduction to Classes, Objects, \n",
      "Member Functions and Strings \n",
      " 113\n",
      "3.1\n",
      "Introduction \n",
      " 114\n",
      "3.2\n",
      "Test-Driving an Account Object \n",
      " 115\n",
      "3.2.1\n",
      "Instantiating an Object \n",
      " 115\n",
      "3.2.2\n",
      "Headers and Source-Code Files \n",
      " 116\n",
      "3.2.3\n",
      "Calling Class Account’s getName Member Function \n",
      " 116\n",
      "3.2.4\n",
      "Inputting a string with getline \n",
      " 117\n",
      "3.2.5\n",
      "Calling Class Account’s setName Member Function \n",
      " 117\n",
      "3.3\n",
      "Account Class with a Data Member and Set and Get Member Functions \n",
      " 118\n",
      "3.3.1\n",
      "Account Class Definition \n",
      " 118\n",
      "3.3.2\n",
      "Keyword class and the Class Body \n",
      " 119\n",
      "3.3.3\n",
      "Data Member name of Type string \n",
      " 119\n",
      "3.3.4\n",
      "setName Member Function \n",
      " 120\n",
      "3.3.5\n",
      "getName Member Function \n",
      " 122\n",
      "3.3.6\n",
      "Access Specifiers private and public \n",
      " 122\n",
      "3.3.7\n",
      "Account UML Class Diagram \n",
      " 123\n",
      "3.4\n",
      "Account Class: Initializing Objects with Constructors \n",
      " 124\n",
      "3.4.1\n",
      "Defining an Account Constructor for Custom Object Initialization  125\n",
      "3.4.2\n",
      "Initializing Account Objects When They’re Created \n",
      " 126\n",
      "3.4.3\n",
      "Account UML Class Diagram with a Constructor \n",
      " 128\n",
      "3.5\n",
      "Software Engineering with Set and Get Member Functions \n",
      " 128\n",
      "3.6\n",
      "Account Class with a Balance; Data Validation \n",
      " 129\n",
      "3.6.1\n",
      "Data Member balance \n",
      " 129\n",
      "3.6.2\n",
      "Two-Parameter Constructor with Validation \n",
      " 131\n",
      "3.6.3\n",
      "deposit Member Function with Validation \n",
      " 131\n",
      "3.6.4\n",
      "getBalance Member Function \n",
      " 131\n",
      "3.6.5\n",
      "Manipulating Account Objects with Balances \n",
      " 132\n",
      "3.6.6\n",
      "Account UML Class Diagram with a Balance and Member \n",
      "Functions deposit and getBalance \n",
      " 134\n",
      "3.7\n",
      "Wrap-Up \n",
      " 134\n",
      "\n",
      "Page 9:\n",
      "  Text blocks: 2\n",
      "  Images: 0\n",
      "Contents\n",
      "9\n",
      "4\n",
      "Algorithm Development and \n",
      "Control Statements: Part 1 \n",
      " 143\n",
      "4.1\n",
      "Introduction \n",
      " 144\n",
      "4.2\n",
      "Algorithms \n",
      " 145\n",
      "4.3\n",
      "Pseudocode \n",
      " 145\n",
      "4.4\n",
      "Control Structures \n",
      " 146\n",
      "4.4.1\n",
      "Sequence Structure \n",
      " 146\n",
      "4.4.2\n",
      "Selection Statements \n",
      " 148\n",
      "4.4.3\n",
      "Iteration Statements \n",
      " 148\n",
      "4.4.4\n",
      "Summary of Control Statements \n",
      " 149\n",
      "4.5\n",
      "if Single-Selection Statement \n",
      " 149\n",
      "4.6\n",
      "if…else Double-Selection Statement \n",
      " 150\n",
      "4.6.1\n",
      "Nested if…else Statements \n",
      " 151\n",
      "4.6.2\n",
      "Dangling-else Problem \n",
      " 153\n",
      "4.6.3\n",
      "Blocks \n",
      " 153\n",
      "4.6.4\n",
      "Conditional Operator (?:) \n",
      " 154\n",
      "4.7\n",
      "Student Class: Nested if…else Statements \n",
      " 155\n",
      "4.8\n",
      "while Iteration Statement \n",
      " 157\n",
      "4.9\n",
      "Formulating Algorithms: Counter-Controlled Iteration \n",
      " 159\n",
      "4.9.1\n",
      "Pseudocode Algorithm with Counter-Controlled Iteration \n",
      " 159\n",
      "4.9.2\n",
      "Implementing Counter-Controlled Iteration \n",
      " 160\n",
      "4.9.3\n",
      "Notes on Integer Division and Truncation \n",
      " 162\n",
      "4.9.4\n",
      "Arithmetic Overflow \n",
      " 162\n",
      "4.9.5\n",
      "Input Validation \n",
      " 163\n",
      "4.10\n",
      "Formulating Algorithms: Sentinel-Controlled Iteration \n",
      " 163\n",
      "4.10.1\n",
      "Top-Down, Stepwise Refinement: The Top and First Refinement  164\n",
      "4.10.2\n",
      "Proceeding to the Second Refinement \n",
      " 164\n",
      "4.10.3\n",
      "Implementing Sentinel-Controlled Iteration \n",
      " 166\n",
      "4.10.4\n",
      "Converting Between Fundamental Types Explicitly and Implicitly  169\n",
      "4.10.5\n",
      "Formatting Floating-Point Numbers \n",
      " 170\n",
      "4.10.6\n",
      "Unsigned Integers and User Input \n",
      " 170\n",
      "4.11\n",
      "Formulating Algorithms: Nested Control Statements \n",
      " 171\n",
      "4.11.1\n",
      "Problem Statement \n",
      " 171\n",
      "4.11.2\n",
      "Top-Down, Stepwise Refinement: Pseudocode Representation \n",
      "of the Top \n",
      " 172\n",
      "4.11.3\n",
      "Top-Down, Stepwise Refinement: First Refinement \n",
      " 172\n",
      "4.11.4\n",
      "Top-Down, Stepwise Refinement: Second Refinement \n",
      " 172\n",
      "4.11.5\n",
      "Complete Second Refinement of the Pseudocode \n",
      " 173\n",
      "4.11.6\n",
      "Program That Implements the Pseudocode Algorithm \n",
      " 174\n",
      "4.11.7\n",
      "Preventing Narrowing Conversions with List Initialization \n",
      " 175\n",
      "4.12\n",
      "Compound Assignment Operators \n",
      " 176\n",
      "4.13\n",
      "Increment and Decrement Operators \n",
      " 177\n",
      "4.14\n",
      "Fundamental Types Are Not Portable \n",
      " 180\n",
      "4.15\n",
      "Wrap-Up \n",
      " 180\n",
      "\n",
      "Page 10:\n",
      "  Text blocks: 2\n",
      "  Images: 0\n"
     ]
    }
   ],
   "source": [
    "for page_num in range(10):#len(doc)):\n",
    "    page = doc[page_num]\n",
    "    print(page.get_text())    # Get text with formatting\n",
    "    text = page.get_text()\n",
    "    \n",
    "    # Get text with font info (bold, size, etc.)\n",
    "    blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "    \n",
    "    # Get images\n",
    "    images = page.get_images()\n",
    "    \n",
    "    print(f\"Page {page_num + 1}:\")\n",
    "    print(f\"  Text blocks: {len(blocks)}\")\n",
    "    print(f\"  Images: {len(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49dbea96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images on page 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "597371"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: image_page1_1.jpeg\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "# Extract images from a specific page\n",
    "page_num = 0  # First page\n",
    "page = doc[page_num]\n",
    "\n",
    "# Get all images on the page\n",
    "images = page.get_images()\n",
    "\n",
    "print(f\"Found {len(images)} images on page {page_num + 1}\")\n",
    "\n",
    "# Extract each image\n",
    "for img_index, img in enumerate(images):\n",
    "    # Get image reference\n",
    "    xref = img[0]\n",
    "    \n",
    "    # Extract image bytes\n",
    "    base_image = doc.extract_image(xref)\n",
    "    image_bytes = base_image[\"image\"]\n",
    "    image_ext = base_image[\"ext\"]  # png, jpeg, etc.\n",
    "    \n",
    "    # Save image to file\n",
    "    with open(f\"image_page{page_num + 1}_{img_index + 1}.{image_ext}\", \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "    \n",
    "    print(f\"✓ Saved: image_page{page_num + 1}_{img_index + 1}.{image_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968dce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "import pdfplumber\n",
    "import tiktoken\n",
    "\n",
    "def chunk_pdf_for_rag(\n",
    "    pdf_path: str,\n",
    "    max_tokens: int = 500,\n",
    "    overlap_tokens: int = 75,\n",
    "    encoding_name: str = \"cl100k_base\"\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Token-accurate, sentence-based chunking for RAG.\n",
    "    Returns chunks with page range and chapter metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    enc = tiktoken.get_encoding(encoding_name)\n",
    "\n",
    "    def count_tokens(text: str) -> int:\n",
    "        return len(enc.encode(text))\n",
    "\n",
    "    def detect_chapter(text: str):\n",
    "        match = re.search(r'\\b(chapter|chap)\\s+(\\d+)\\b', text, re.IGNORECASE)\n",
    "        return int(match.group(2)) if match else None\n",
    "\n",
    "    def split_into_sentences(text: str) -> List[str]:\n",
    "        return re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_tokens = 0\n",
    "    current_chapter = None\n",
    "    chunk_start_page = None\n",
    "\n",
    "    i = 0\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages, start=1):\n",
    "            raw_text = page.extract_text() or \"\"\n",
    "            sentences = split_into_sentences(raw_text)\n",
    "\n",
    "            for sentence in sentences:\n",
    "                sentence = sentence.strip()\n",
    "                if not sentence:\n",
    "                    continue\n",
    "\n",
    "                # Detect chapter headings\n",
    "                chapter = detect_chapter(sentence)\n",
    "                if chapter is not None and chapter != current_chapter:\n",
    "                    # Flush chunk on chapter boundary\n",
    "                    if current_chunk.strip():\n",
    "                        chunks.append({\n",
    "                            \"text\": current_chunk.strip(),\n",
    "                            \"page_start\": chunk_start_page,\n",
    "                            \"page_end\": page_num,\n",
    "                            \"chapter_index\": current_chapter,\n",
    "                            \"chunk_type\": \"text\"\n",
    "                        })\n",
    "\n",
    "                    current_chunk = \"\"\n",
    "                    current_tokens = 0\n",
    "                    current_chapter = chapter\n",
    "                    chunk_start_page = None\n",
    "\n",
    "                sentence_tokens = count_tokens(sentence)\n",
    "                # Initialize chunk start page\n",
    "                if current_chunk == \"\":\n",
    "                    chunk_start_page = page_num\n",
    "\n",
    "                # FIX: Check if adding this sentence would exceed limit\n",
    "                if current_tokens + sentence_tokens > max_tokens:\n",
    "                    # Emit current chunk (only if not empty)\n",
    "                    if current_chunk.strip():\n",
    "                        chunks.append({\n",
    "                            \"text\": current_chunk.strip(),\n",
    "                            \"page_start\": chunk_start_page,\n",
    "                            \"page_end\": page_num,\n",
    "                            \"chapter_index\": current_chapter,\n",
    "                            \"chunk_type\": \"text\"\n",
    "                        })\n",
    "\n",
    "                    # Create overlap from previous chunk\n",
    "                    if current_chunk.strip():\n",
    "                        overlap_text = enc.decode(\n",
    "                            enc.encode(current_chunk)[-overlap_tokens:]\n",
    "                        )\n",
    "                    else:\n",
    "                        overlap_text = \"\"\n",
    "\n",
    "                    # Start new chunk with overlap + current sentence\n",
    "                    current_chunk = (overlap_text + \" \" + sentence).strip() + \" \"\n",
    "                    current_tokens = count_tokens(current_chunk)\n",
    "                    chunk_start_page = page_num\n",
    "                    \n",
    "                    # FIX: If even the new chunk with overlap exceeds limit, \n",
    "                    # start fresh without overlap\n",
    "                    if current_tokens > max_tokens:\n",
    "                        current_chunk = sentence + \" \"\n",
    "                        current_tokens = sentence_tokens\n",
    "                else:\n",
    "                    # Add sentence to current chunk\n",
    "                    current_chunk += sentence + \" \"\n",
    "                    current_tokens += sentence_tokens\n",
    "                \n",
    "    if current_chunk.strip():\n",
    "        chunks.append({\n",
    "            \"text\": current_chunk.strip(),\n",
    "            \"page_start\": chunk_start_page,\n",
    "            \"page_end\": page_num,\n",
    "            \"chapter_index\": current_chapter,\n",
    "            \"chunk_type\": \"text\"\n",
    "        })\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3961b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"E:\\Semester 5\\ML\\Machine_Learning_Project\\Project.pdf\"\n",
    "\n",
    "chunks= chunk_pdf_for_rag(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fffd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chk in chunks[ 50: 55]: \n",
    "    print(len(chk['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53c4409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'National University of Computer and Emerging Sciences\\nIslamabad Campus\\nDepartment of AI & DS (fall-2025)\\nMachine Learning Lab- Projects\\nProject Guidelines\\n• Each group must consist of 2 members only. • Read the project description carefully before starting your work. • Make sure every member clearly understands the problem statement, dataset, and\\nexpected outcomes. • Clarify any doubts with the instructor before implementation. • The project must be original — plagiarism from classmates, previous projects, or online\\nsources will result in zero marks for all group members. • You may refer to tutorials or documentation for learning, but the final implementation\\nand report must be your own work. • Only one member per group will upload/submit the project. • The submission should include:\\no Code file (.ipynb or .py)\\no Project report (PDF format)\\no A ReadMe file with:\\n▪ Group members’ names and roll numbers\\n▪ Short description of the project\\n▪ Required libraries/dependencies\\n▪ Instructions to run the code\\n• All members must participate in the project demo. • Late submissions will not be accepted unless prior approval is granted with a valid\\nreason. • Ensure your files are properly named and uploaded in the correct format. • Distribute the work equally among group members. • Report any group-related issues well before the deadline. Project Title: MovieInsightML – Revenue Forecasting & Genre Classification\\nUsing Text and Numeric Features\\nProject Description:\\nE-commerce platforms and digital content services often contain large amounts of descriptive\\ntext along with numeric product or item attributes. In this project, we use a movie dataset that\\nincludes overview text, budget, revenue, ratings, popularity, and other numerical attributes. The\\ngoal is to build a machine learning system that can predict a movie’s revenue (regression) and\\nclassify its main genre (classification) using a combination of textual features extracted from\\nthe movie overview and continuous numeric features. This integrates text processing with\\nnumerical feature engineering and provides hands-on experience with mixed-type data and both\\npredictive tasks. Tasks to be Completed:\\n1. Data Preparation:\\n• Load and explore the given dataset\\n• Perform data cleaning:\\no Handle missing values in overview text or numeric columns. o Remove duplicates or irrelevant entries. • Feature extraction & engineering:\\no From overview text: word count, average word length, sentiment score.',\n",
       "  'page_start': 1,\n",
       "  'page_end': 2,\n",
       "  'chapter_index': None,\n",
       "  'chunk_type': 'text'},\n",
       " {'text': 'experience with mixed-type data and both\\npredictive tasks. Tasks to be Completed:\\n1. Data Preparation:\\n• Load and explore the given dataset\\n• Perform data cleaning:\\no Handle missing values in overview text or numeric columns. o Remove duplicates or irrelevant entries. • Feature extraction & engineering:\\no From overview text: word count, average word length, sentiment score.  o From numeric features: budget (continuous), popularity (continuous), runtime\\n(continuous), vote_average (continuous), vote_count (continuous). o Extract the main genre from the genres column (first genre in the list). • Define two target variables:\\no target: movie revenue (continuous). o target: main movie genre. • Normalize continuous numeric features for regression/classification. • Convert overview text into features using TF-IDF vectorization. 2. Model Training and Evaluation:\\n• Regression models to forecast movie revenue: Linear Regression, Decision Tree\\nRegressor, Random Forest Regressor. • Classification models to predict main movie genre: Logistic Regression, KNN, Decision\\nTree Classifier, Random Forest Classifier. • Use k-fold cross-validation for both. • Report metrics for regression: MAE, RMSE, R². • Report metrics for classification: Accuracy, Precision, Recall, F1-score, Confusion\\nMatrix. • Compare results and identify best models for each task. TinyML Deployment:\\n• Convert the trained regression or classification model into TensorFlow Lite (TFLite)\\nformat. • Evaluate the model size reduction and inference speed improvement after conversion. • Upload the .tflite model to an online TinyML platform (e.g., Edge Impulse) to check:\\no RAM usage\\no Flash/storage usage\\no Latency on simulated edge devices\\n• Compare the original model and TinyML model to demonstrate feasibility of deploying\\nML on low-power hardware. Bonus Tasks:\\n• Visualize how review length, sentiment, or numeric features relate to movie revenue or\\ngenre. • Cluster reviews using K-Means or hierarchical clustering based on TF-IDF features to\\nidentify patterns. • Detect outliers using anomaly detection techniques and analyze their impact. Expected Learning Outcomes:\\n• Handle mixed-type data (text + continuous numeric). • Perform text preprocessing, feature extraction from text, and integrate with numeric\\nfeatures. • Apply both regression and classification tasks in one project. • Evaluate and interpret model performance using appropriate metrics and visuals. • Gain actionable insights from combined text+numeric data.',\n",
       "  'page_start': 2,\n",
       "  'page_end': 3,\n",
       "  'chapter_index': None,\n",
       "  'chunk_type': 'text'},\n",
       " {'text': 'detection techniques and analyze their impact. Expected Learning Outcomes:\\n• Handle mixed-type data (text + continuous numeric). • Perform text preprocessing, feature extraction from text, and integrate with numeric\\nfeatures. • Apply both regression and classification tasks in one project. • Evaluate and interpret model performance using appropriate metrics and visuals. • Gain actionable insights from combined text+numeric data.  Final Deliverables\\nEach group is required to submit the following components as part of the final project\\nsubmission:\\n• Jupyter Notebook (.ipynb):\\n• The notebook must include the complete implementation of your project. • Ensure that the code is well-commented and easy to follow. • All outputs, visualizations, and evaluation results should be clearly displayed and\\nproperly labeled. • The notebook should present a complete workflow covering:\\no Data loading and exploration\\no Data preprocessing and feature engineering\\no Model training and testing\\no Evaluation and performance analysis\\n• Use markdown headings, explanations, and visualizations for clarity and readability. • Project Report (.pdf ):\\n• Prepare a report of approximately 5–7 pages summarizing your project work. • The report should be clear, concise, and well-formatted. • It must include the following sections:\\no Introduction (background, motivation, objectives)\\no Dataset Description (source, size, features, and attributes)\\no Data Preprocessing (cleaning, encoding, and scaling)\\no Feature Engineering (feature creation or transformations)\\no Algorithms and Models (overview and selection reasons)\\no Results and Evaluation (performance metrics and visualizations)\\no Discussion (analysis of results, limitations, and observations)\\no Conclusion (key findings and future improvements)\\n• Include readable figures, tables, and proper references if any sources are cited. • Submission Instructions:\\n• Upload your Jupyter Notebook (.ipynb) and Report (.pdf or .docx) separately on\\nGoogle Classroom (GcR). • Do not compress or zip the files. • Both files must have the same name using the following format:\\nProjectTitle_GroupNumber\\n(Example: SmartNewsML_Group05.ipynb and SmartNewsML_Group05.pdf)\\n• Only one member per group should upload the files. • Late or incomplete submissions will not be accepted.',\n",
       "  'page_start': 3,\n",
       "  'page_end': 4,\n",
       "  'chapter_index': None,\n",
       "  'chunk_type': 'text'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from typing import List, Dict, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import Tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "\n",
    "class chatState(Dict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    llm: None\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    llm = ChatGroq(model=\"moonshotai/kimi-k2-instruct-0905\")\n",
    "    return {'llm': llm}\n",
    "\n",
    "\n",
    "def chat(chat_state: chatState):\n",
    "    response = llm.invoke(chat_state[\"messages\"])\n",
    "    return {\"messages\": [response]}    \n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    res = DuckDuckGoSearchRun().invoke(query)\n",
    "    return res\n",
    "\n",
    "tools=[search]\n",
    "tool_node = ToolNode(tools)\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = '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'\n",
    "\n",
    "llm_with_tools = llm.bind(tools)\n",
    "\n",
    "graph = StateGraph(chatState)   \n",
    "\n",
    "\n",
    "graph.add_node(\"chat\", chat)\n",
    "\n",
    "graph.add_edge(START, \"chat\")\n",
    "graph.add_edge(\"chat\", tools_cond)\n",
    "\n",
    "chatbot = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc7600b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "790d1939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who is Quaid e azam?', additional_kwargs={}, response_metadata={}, id='58a94c9b-2b46-4f8c-b6b8-04ce0cd421f1'),\n",
       "  AIMessage(content='Quaid-e-Azam (Urdu for “Great Leader”) is the title given to Muhammad Ali Jinnah, the founder of Pakistan. Born on 25 December 1876 in Karachi, he trained as a barrister in London and became one of India’s most successful lawyers. Jinnah entered politics as a secular nationalist in the Indian National Congress but later joined the All-India Muslim League, arguing that Muslims constituted a separate nation that needed its own state to avoid being dominated by a Hindu-majority independent India. After years of negotiations—especially with the Indian National Congress and the British Raj—he led the demand for a separate homeland for Muslims, culminating in the creation of Pakistan on 14 August 1947. He served as the new nation’s first Governor-General until his death on 11 September 1948.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 34, 'total_tokens': 204, 'completion_time': 0.611871075, 'completion_tokens_details': None, 'prompt_time': 0.010081193, 'prompt_tokens_details': None, 'queue_time': 0.19695045, 'total_time': 0.621952268}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_5fe129dff6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b514b-5804-70a2-baff-a0937600213d-0', usage_metadata={'input_tokens': 34, 'output_tokens': 170, 'total_tokens': 204})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a helpful assistant.\n",
    "\"\"\"\n",
    "chatbot.invoke({\"messages\": [HumanMessage(content=\"who is Quaid e azam?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c47327fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'id': 'openai/gpt-oss-20b',\n",
       "   'object': 'model',\n",
       "   'created': 1754407957,\n",
       "   'owned_by': 'OpenAI',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 65536},\n",
       "  {'id': 'meta-llama/llama-4-maverick-17b-128e-instruct',\n",
       "   'object': 'model',\n",
       "   'created': 1743877158,\n",
       "   'owned_by': 'Meta',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 8192},\n",
       "  {'id': 'moonshotai/kimi-k2-instruct-0905',\n",
       "   'object': 'model',\n",
       "   'created': 1757046093,\n",
       "   'owned_by': 'Moonshot AI',\n",
       "   'active': True,\n",
       "   'context_window': 262144,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 16384},\n",
       "  {'id': 'whisper-large-v3',\n",
       "   'object': 'model',\n",
       "   'created': 1693721698,\n",
       "   'owned_by': 'OpenAI',\n",
       "   'active': True,\n",
       "   'context_window': 448,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 448},\n",
       "  {'id': 'openai/gpt-oss-120b',\n",
       "   'object': 'model',\n",
       "   'created': 1754408224,\n",
       "   'owned_by': 'OpenAI',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 65536},\n",
       "  {'id': 'canopylabs/orpheus-arabic-saudi',\n",
       "   'object': 'model',\n",
       "   'created': 1765926439,\n",
       "   'owned_by': 'Canopy Labs',\n",
       "   'active': True,\n",
       "   'context_window': 200,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 50000},\n",
       "  {'id': 'canopylabs/orpheus-v1-english',\n",
       "   'object': 'model',\n",
       "   'created': 1766186316,\n",
       "   'owned_by': 'Canopy Labs',\n",
       "   'active': True,\n",
       "   'context_window': 200,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 50000},\n",
       "  {'id': 'meta-llama/llama-prompt-guard-2-22m',\n",
       "   'object': 'model',\n",
       "   'created': 1748632101,\n",
       "   'owned_by': 'Meta',\n",
       "   'active': True,\n",
       "   'context_window': 512,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 512},\n",
       "  {'id': 'llama-3.1-8b-instant',\n",
       "   'object': 'model',\n",
       "   'created': 1693721698,\n",
       "   'owned_by': 'Meta',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 131072},\n",
       "  {'id': 'meta-llama/llama-4-scout-17b-16e-instruct',\n",
       "   'object': 'model',\n",
       "   'created': 1743874824,\n",
       "   'owned_by': 'Meta',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 8192},\n",
       "  {'id': 'allam-2-7b',\n",
       "   'object': 'model',\n",
       "   'created': 1737672203,\n",
       "   'owned_by': 'SDAIA',\n",
       "   'active': True,\n",
       "   'context_window': 4096,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 4096},\n",
       "  {'id': 'playai-tts-arabic',\n",
       "   'object': 'model',\n",
       "   'created': 1740682783,\n",
       "   'owned_by': 'PlayAI',\n",
       "   'active': True,\n",
       "   'context_window': 10000,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 8192},\n",
       "  {'id': 'groq/compound',\n",
       "   'object': 'model',\n",
       "   'created': 1756949530,\n",
       "   'owned_by': 'Groq',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 8192},\n",
       "  {'id': 'qwen/qwen3-32b',\n",
       "   'object': 'model',\n",
       "   'created': 1748396646,\n",
       "   'owned_by': 'Alibaba Cloud',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 40960},\n",
       "  {'id': 'moonshotai/kimi-k2-instruct',\n",
       "   'object': 'model',\n",
       "   'created': 1752435491,\n",
       "   'owned_by': 'Moonshot AI',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 16384},\n",
       "  {'id': 'playai-tts',\n",
       "   'object': 'model',\n",
       "   'created': 1740682771,\n",
       "   'owned_by': 'PlayAI',\n",
       "   'active': True,\n",
       "   'context_window': 10000,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 8192},\n",
       "  {'id': 'whisper-large-v3-turbo',\n",
       "   'object': 'model',\n",
       "   'created': 1728413088,\n",
       "   'owned_by': 'OpenAI',\n",
       "   'active': True,\n",
       "   'context_window': 448,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 448},\n",
       "  {'id': 'meta-llama/llama-guard-4-12b',\n",
       "   'object': 'model',\n",
       "   'created': 1746743847,\n",
       "   'owned_by': 'Meta',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 1024},\n",
       "  {'id': 'meta-llama/llama-prompt-guard-2-86m',\n",
       "   'object': 'model',\n",
       "   'created': 1748632165,\n",
       "   'owned_by': 'Meta',\n",
       "   'active': True,\n",
       "   'context_window': 512,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 512},\n",
       "  {'id': 'groq/compound-mini',\n",
       "   'object': 'model',\n",
       "   'created': 1756949707,\n",
       "   'owned_by': 'Groq',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 8192},\n",
       "  {'id': 'openai/gpt-oss-safeguard-20b',\n",
       "   'object': 'model',\n",
       "   'created': 1761708789,\n",
       "   'owned_by': 'OpenAI',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 65536},\n",
       "  {'id': 'llama-3.3-70b-versatile',\n",
       "   'object': 'model',\n",
       "   'created': 1733447754,\n",
       "   'owned_by': 'Meta',\n",
       "   'active': True,\n",
       "   'context_window': 131072,\n",
       "   'public_apps': None,\n",
       "   'max_completion_tokens': 32768}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "url = \"https://api.groq.com/openai/v1/models\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c01ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
