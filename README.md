# ğŸ¤– Agentic RAG Chatbot

A powerful Retrieval-Augmented Generation (RAG) chatbot built with **LangGraph**, **Pinecone**, and **Next.js**. Upload PDF documents and ask intelligent questions powered by AI agents that can search both your documents and the web.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Next.js](https://img.shields.io/badge/next.js-16.0-black.svg)

## âœ¨ Features

### ğŸ¯ Core Functionality
- **ğŸ“„ PDF Document Upload**: Upload and process PDF files with intelligent chunking
- **ğŸ” Smart Search**: AI-powered search across uploaded documents
- **ğŸŒ Web Search Integration**: DuckDuckGo search for real-time information
- **ğŸ’¬ Conversational AI**: Context-aware responses using LangGraph agents
- **ğŸ—‘ï¸ Document Management**: Delete documents and their vector embeddings
- **ğŸ‘¤ User Authentication**: Secure login/register system with session management
- **ğŸ“Š Real-time Progress**: Live upload progress tracking
- **ğŸ’¾ Persistent Storage**: Documents persist across sessions

### ğŸ› ï¸ Technical Features
- **Agentic Architecture**: LangGraph-based agent workflow
- **Vector Search**: Pinecone vector database for semantic search
- **Token-Accurate Chunking**: Smart PDF chunking with sentence boundaries
- **Multi-User Support**: Isolated document spaces per user
- **RESTful API**: Clean Flask backend with blueprints
- **Modern UI**: Responsive Next.js frontend with TypeScript

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (Next.js)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Auth UI    â”‚  â”‚   Chat UI    â”‚  â”‚  Upload UI   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼ HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Backend (Flask)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Auth Routes â”‚  â”‚  Chat Routes â”‚  â”‚Upload Routes â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                            â–¼                                 â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                   â”‚ LangGraph Agent  â”‚                       â”‚
â”‚                   â”‚  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”‚                       â”‚
â”‚                   â”‚  â”‚PDF â”‚  â”‚Web â”‚  â”‚                       â”‚
â”‚                   â”‚  â”‚Toolâ”‚  â”‚Toolâ”‚  â”‚                       â”‚
â”‚                   â”‚  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â”‚                       â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Services                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Pinecone   â”‚  â”‚     Groq     â”‚  â”‚  DuckDuckGo  â”‚      â”‚
â”‚  â”‚ Vector Store â”‚  â”‚   LLM API    â”‚  â”‚    Search    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Prerequisites

- **Python**: 3.10 or higher
- **Node.js**: 18.0 or higher
- **npm**: 9.0 or higher
- **Pinecone Account**: [Sign up here](https://www.pinecone.io/)
- **Groq API Key**: [Get it here](https://console.groq.com/)

---

## ğŸš€ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Hamza0590/Agentic-_Rag_Chatbot.git
cd Agentic_project
```

### 2ï¸âƒ£ Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# Windows:
.\venv\Scripts\Activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3ï¸âƒ£ Frontend Setup

```bash
# Navigate to frontend directory
cd ../frontend

# Install dependencies
npm install
```

### 4ï¸âƒ£ Environment Configuration

Create a `.env` file in the **backend** directory:

```env
# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here

# Groq API Configuration
GROQ_API_KEY=your_groq_api_key_here

# Flask Configuration
SECRET_KEY=your_secret_key_change_this_in_production
FLASK_ENV=development
```

**âš ï¸ Important**: Replace the placeholder values with your actual API keys.

---

## ğŸ® Running the Application

### Option 1: Run Both Servers Together (Recommended)

```bash
# From the frontend directory
npm run dev:all
```

This command starts:
- **Frontend**: http://localhost:3000
- **Backend**: http://localhost:5000

### Option 2: Run Servers Separately

**Terminal 1 - Backend:**
```bash
cd backend
flask run
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

---

## ğŸ“– Usage Guide

### 1. **Register/Login**
- Navigate to `http://localhost:3000`
- Create a new account or login with existing credentials

### 2. **Upload Documents**
- Click the **Upload Document** button or the **+** icon in the sidebar
- Select a PDF file (supports `.pdf`, `.epub`, `.txt`)
- Watch the real-time upload progress
- Document will appear in the sidebar once ready

### 3. **Ask Questions**
- Type your question in the chat input
- The AI will automatically:
  - Search your uploaded documents for relevant information
  - Search the web if needed for current information
  - Provide a comprehensive answer with citations

### 4. **Manage Documents**
- View all uploaded documents in the sidebar
- Click the **trash icon** to delete a document
- Deletion removes both the document and its vector embeddings

### 5. **Logout**
- Click the **Logout** button
- All your document vectors are automatically cleaned up

---

## ğŸ”§ API Endpoints

### Authentication

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/register` | Register a new user |
| POST | `/login` | Login existing user |
| POST | `/logout` | Logout and cleanup vectors |

### Document Management

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/upload_file` | Upload and process PDF |
| DELETE | `/delete_document` | Delete document and vectors |

### Chat

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/chat` | Send query and get AI response |

---

## ğŸ§  How It Works

### PDF Processing Pipeline

1. **Upload**: User uploads PDF via frontend
2. **Chunking**: PDF is split into semantic chunks (500 tokens max)
3. **Embedding**: Chunks are converted to vector embeddings using HuggingFace
4. **Storage**: Vectors stored in Pinecone with metadata (source, page, user)
5. **Ready**: Document available for querying

### Query Processing Pipeline

1. **User Query**: User asks a question
2. **Agent Decision**: LangGraph agent decides which tool to use:
   - **PDF Tool**: Search uploaded documents
   - **Web Tool**: Search DuckDuckGo
3. **Retrieval**: Relevant information retrieved
4. **Generation**: LLM generates answer using retrieved context
5. **Response**: Answer sent back to user with citations

---

## ğŸ—‚ï¸ Project Structure

```
Agentic_project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py              # Flask app initialization
â”‚   â”‚   â”œâ”€â”€ models.py                # Database models
â”‚   â”‚   â”œâ”€â”€ langraph_pipeline.py     # LangGraph agent setup
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ auth.py              # Authentication routes
â”‚   â”‚       â”œâ”€â”€ chat.py              # Chat routes
â”‚   â”‚       â””â”€â”€ upload.py            # Upload & delete routes
â”‚   â”œâ”€â”€ instance/
â”‚   â”‚   â””â”€â”€ chatbot.db               # SQLite database
â”‚   â”œâ”€â”€ main.py                      # Flask entry point
â”‚   â””â”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx                 # Landing/Auth page
â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx             # Chat interface
â”‚   â”‚   â”‚   â””â”€â”€ chat.css             # Chat styles
â”‚   â”‚   â”œâ”€â”€ globals.css              # Global styles
â”‚   â”‚   â””â”€â”€ layout.tsx               # Root layout
â”‚   â”œâ”€â”€ package.json                 # Node dependencies
â”‚   â””â”€â”€ tsconfig.json                # TypeScript config
â”‚
â”œâ”€â”€ .env                             # Environment variables
â””â”€â”€ README.md                        # This file
```

---

## ğŸ›¡ï¸ Security Considerations

- âœ… User authentication with session management
- âœ… User-isolated document storage (session_id filtering)
- âœ… API key protection via environment variables
- âœ… CORS enabled for frontend-backend communication
- âš ï¸ **Note**: Current implementation uses plain text passwords (use bcrypt in production)
- âš ï¸ **Note**: Change `SECRET_KEY` in production

---

## ğŸ”‘ Key Technologies

### Backend
- **Flask**: Web framework
- **LangGraph**: Agent orchestration framework
- **LangChain**: LLM integration
- **Pinecone**: Vector database
- **HuggingFace**: Embeddings model
- **Groq**: LLM API (GPT-OSS-120B)
- **pdfplumber**: PDF text extraction
- **tiktoken**: Token counting
- **SQLAlchemy**: ORM for user management

### Frontend
- **Next.js 16**: React framework
- **TypeScript**: Type safety
- **React Markdown**: Markdown rendering
- **Tailwind CSS**: Styling
- **XMLHttpRequest**: Upload progress tracking

---

## ğŸ“Š Features in Detail

### Smart PDF Chunking
- **Token-accurate**: Uses tiktoken for precise token counting
- **Sentence-based**: Respects sentence boundaries
- **Overlap**: 75-token overlap for context preservation
- **Chapter detection**: Identifies chapter boundaries
- **Metadata**: Tracks page numbers and source

### Agentic Workflow
```python
# LangGraph agent with two tools:
- search_pdfs: Searches uploaded documents
- search_ddgo: Searches the web

# Agent automatically decides which tool to use based on query
```

### Vector Search
- **Similarity search**: Finds top-k most relevant chunks
- **User filtering**: Only searches user's documents
- **Metadata filtering**: Filter by source, page, chapter

---

## ğŸ› Troubleshooting

### Backend won't start
```bash
# Check if port 5000 is available
netstat -ano | findstr :5000

# Try a different port
flask run --port 5001
```

### Frontend won't start
```bash
# Clear node modules and reinstall
rm -rf node_modules package-lock.json
npm install
```

### Upload fails
- Check file size (large PDFs may timeout)
- Verify Pinecone API key is correct
- Check backend logs for errors

### No search results
- Verify documents are uploaded successfully
- Check if user email is being sent in headers
- Verify Pinecone index name is "books-index"

---

## ğŸš§ Future Enhancements

- [ ] Password hashing with bcrypt
- [ ] JWT authentication
- [ ] Multiple file upload
- [ ] Chat history persistence
- [ ] Export chat conversations
- [ ] Support for more file formats (DOCX, TXT, EPUB)
- [ ] Streaming responses
- [ ] Citation highlighting
- [ ] Dark/Light theme toggle
- [ ] Mobile responsive improvements

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ‘¨â€ğŸ’» Author

**Hamza**
- GitHub: [@Hamza0590](https://github.com/Hamza0590)
- Repository: [Agentic-_Rag_Chatbot](https://github.com/Hamza0590/Agentic-_Rag_Chatbot)

---

## ğŸ™ Acknowledgments

- **LangChain** for the amazing LLM framework
- **Pinecone** for vector database
- **Groq** for fast LLM inference
- **Vercel** for Next.js framework

---

## ğŸ“ Support

If you encounter any issues or have questions:
1. Check the [Troubleshooting](#-troubleshooting) section
2. Open an issue on GitHub
3. Review the code documentation

---

**â­ If you find this project helpful, please give it a star!**
